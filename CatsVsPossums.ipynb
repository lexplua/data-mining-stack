{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b100ddb744c0b4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86292372-f89b-420c-871d-59dc2d02ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from torchvision import transforms, models\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7441bfa15e090ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Set up MLflow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c470f0-fef0-4ea7-9b14-db41d93958c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-dwh/4', creation_time=1693158451661, experiment_id='4', last_update_time=1693158451661, lifecycle_stage='active', name='Cats vs Possums', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"1234\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] =\"123441212344321\"\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL']=\"http://localhost:9000\"\n",
    "mlflow.set_tracking_uri('http://localhost:5000/')\n",
    "mlflow.set_experiment('Cats vs Possums')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853d3a540f1b264",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Define data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3cf718-7ea1-4752-92dd-824f8cc0d520",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_transforms ={\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomHorizontalFlip(p=0.9),\n",
    "        transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], ),\n",
    "    ]),\n",
    "    \n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], ),\n",
    "    ]),\n",
    "    \n",
    "    'test':transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], ),\n",
    "    ]),\n",
    "    \n",
    "}\n",
    "\n",
    "dataset = {\n",
    "    key: torchvision.datasets.ImageFolder(f'./images/{key}', transform=transform)\n",
    "    for key, transform in image_transforms.items()\n",
    "}\n",
    "\n",
    "loader = {\n",
    "    key: data.DataLoader(ds, batch_size=10, shuffle=key=='train')\n",
    "    for key, ds in dataset.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea59303478a5c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Visualisation utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8c2e19-f188-4916-8212-8653deccf21d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show(images: torch.Tensor, labels: List[str], dataset: torchvision.datasets.DatasetFolder):\n",
    "    transform = dataset.transform\n",
    "    classes = dataset.classes\n",
    "    mean = transform.transforms[-1].mean\n",
    "    std = transform.transforms[-1].std\n",
    "    inverse_normalize = transforms.Compose(\n",
    "        [\n",
    "           transforms.Normalize(\n",
    "                mean=tuple(-m / s for m, s in zip(mean, std)),\n",
    "                std=tuple(1.0 / s for s in std),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=len(images), squeeze=False, figsize=(18, 2))\n",
    "    for i, img in enumerate(images):\n",
    "        img = img.detach()\n",
    "        img = inverse_normalize(img)\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        axs[0, i].set_title(classes[labels[i]])\n",
    "    return fig\n",
    "\n",
    "def plot_10_predictions(test_loader: data.DataLoader, classifier: torch.nn.Module):\n",
    "    test_data = next(iter(test_loader))\n",
    "    predictions = classifier(test_data[0])\n",
    "    labels = (predictions > 0.5).to(torch.int)\n",
    "    fig = show(test_data[0], labels, dataset['test'])\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_insights(classifier: torch.nn.Module):\n",
    "    test_results = pd.DataFrame()\n",
    "    with torch.no_grad():\n",
    "        for data, labels in iter(loader['test']):\n",
    "            predictions = classifier(data)\n",
    "            batch = pd.DataFrame({\n",
    "                'y_hat': predictions.numpy().ravel(),\n",
    "                'y': labels.numpy().ravel()\n",
    "            })\n",
    "            test_results = test_results.append(batch)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        test_results['y'],\n",
    "        test_results['y_hat']\n",
    "    )\n",
    "    area = px.area(\n",
    "        x=fpr, y=tpr\n",
    "    )\n",
    "    area.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "    df = pd.DataFrame({\n",
    "        'False Positive Rate': fpr,\n",
    "        'True Positive Rate': tpr\n",
    "    }, index=thresholds)\n",
    "    fig_thresh = px.line(\n",
    "        df, title='TPR and FPR at every threshold'\n",
    "    )\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        subplot_titles=[\n",
    "            f'ROC Curve (AUC={metrics.auc(fpr, tpr):.4f})',\n",
    "            'TPR and FPR at every threshold'\n",
    "        ]\n",
    "    )\n",
    "    fig.add_trace(next(area.select_traces()), row=1, col=1)\n",
    "    fig.update_yaxes(scaleratio=1, row=1, col=1, title_text=\"True Positive Rate\")\n",
    "    fig.update_xaxes(constrain='domain', row=1, col=1, title_text=\"False Positive Rate\")\n",
    "    fig.add_trace(next(fig_thresh.select_traces()), row=1, col=2)\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1, row=1, col=2, title_text=\"Thresholds\")\n",
    "    fig.update_xaxes(range=[0, 1], constrain='domain', row=1, col=2, title_text=\"Rate\")\n",
    "    fig.update_layout(height=400, width=900,\n",
    "                      title_text=\"ROC AUC and Decision threshold\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c65d6a3bd49a16",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab0b9cc-3ec0-411c-9763-82cc66e0ad23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PossumOrCat(pl.LightningModule):\n",
    "    def __init__(self, classifier_layers=None):\n",
    "        super().__init__()\n",
    "        self.pretrain = models.resnet18(pretrained=True)\n",
    "        self.output_features = self.pretrain.fc.in_features   \n",
    "        new_head = self.create_new_output(classifier_layers or [])\n",
    "        self.pretrain.fc = new_head\n",
    "\n",
    "        self.train_accuracy = torchmetrics.Accuracy('binary')\n",
    "        self.validation_accuracy = torchmetrics.Accuracy('binary')\n",
    "        \n",
    "    def create_new_output(self, layers: List[int]):\n",
    "        new_head = []\n",
    "        current_output_size = self.output_features\n",
    "        for layer in layers:\n",
    "            if layer is None:\n",
    "                continue\n",
    "            new_head.append(torch.nn.Dropout(0.5))\n",
    "            new_head.append(torch.nn.Linear(current_output_size, layer))\n",
    "            new_head.append(torch.nn.ReLU())\n",
    "            current_output_size = layer\n",
    "            \n",
    "        # Remove first dropout and last activation\n",
    "        new_head = new_head[1:-1]\n",
    "\n",
    "        # Append new activation function\n",
    "        new_head.append(torch.nn.Linear(current_output_size, 1))\n",
    "        new_head.append(torch.nn.Sigmoid())\n",
    "        return torch.nn.Sequential(*new_head)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.pretrain(x)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "\n",
    "        # Log (log) loss \n",
    "        loss = torch.nn.functional.binary_cross_entropy(y_hat.ravel(), y.to(torch.float))\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        # Log custom metric\n",
    "        self.train_accuracy(y_hat.ravel(), y.to(torch.float))\n",
    "        self.log(\"train_accuracy\", self.train_accuracy)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(y_hat.ravel(), y.to(torch.float))\n",
    "        self.log(\"validation_loss\", loss)\n",
    "\n",
    "         # Log custom metric\n",
    "        self.validation_accuracy(y_hat.ravel(), y.to(torch.float))\n",
    "        self.log(\"validation_accuracy\", self.validation_accuracy)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(y_hat.ravel(), y.to(torch.float))\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178409fd-eb57-4145-834e-ca3c3aaf0d39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mlflow.pytorch.autolog()\n",
    "\n",
    "def run_modeling(layers):\n",
    "    with mlflow.start_run():\n",
    "        # Create and train classifier\n",
    "        clf = PossumOrCat(classifier_layers=layers) \n",
    "        trainer = pl.Trainer(max_epochs=10)\n",
    "        trainer.fit(clf, train_dataloaders=loader['train'], val_dataloaders=loader['validation'])\n",
    "\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"layers\", layers)\n",
    "        \n",
    "        # Log custom metric\n",
    "        test_result = trainer.test(clf, dataloaders=loader['test'], )\n",
    "        mlflow.log_metric('Total test loss', test_result[0]['test_loss'])\n",
    "        \n",
    "        # Log images with predictions\n",
    "        predictions_vs_actuals = plot_10_predictions(loader['test'], classifier=clf)\n",
    "        mlflow.log_figure(predictions_vs_actuals, '10test.png')\n",
    "    \n",
    "        # Log binary charts\n",
    "        insights = plot_insights(classifier=clf)\n",
    "        mlflow.log_figure(insights, 'roc_threshold.html')\n",
    "        \n",
    "\n",
    "candidate_layers = [16, 64, None]\n",
    "for candidate in itertools.product(candidate_layers, repeat=3):\n",
    "    run_modeling(candidate)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4294d84c-0637-4169-ae21-b8291c0befde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PossumOrCat(\n",
       "  (pretrain): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (train_accuracy): BinaryAccuracy()\n",
       "  (validation_accuracy): BinaryAccuracy()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = mlflow.search_runs(order_by=['metrics.validation_loss'], output_format='list')[0]\n",
    "uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "best_model = mlflow.pytorch.load_model(uri)\n",
    "best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
